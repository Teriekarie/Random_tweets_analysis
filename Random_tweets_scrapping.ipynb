{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2027a554",
   "metadata": {},
   "source": [
    "# Task\n",
    "\n",
    "Extract random twitter data for the last one week, a maximum of 200,000 rows. This data should not have any specific hash tags."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a946951",
   "metadata": {},
   "source": [
    "# Methodology\n",
    "\n",
    "Using Snscrape which is a scraper for social networking services (SNS). It scrapes details like user profiles, hashtags, or searches and returns the discovered items, e.g. the relevant posts.\n",
    "\n",
    "Installing and importing the necessary libraries.\n",
    "\n",
    "Setting Variables to be used\n",
    "\n",
    "We will be scraping a minimum number of 200,000 random tweets from twitter. The date is set from 1st Decwmber 2022 to 7th December 2022 in the span of one week. since my Ram isnot enough to scrape it all at once it was then done in batches (from 1st-2nd, 3rd-4th, 5th-6th, 4th-7th, 5th-7th, 6th-7th)\n",
    "\n",
    "Finally merging the different dataframe to a single one and as a CSV file for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24fc3a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: snscrape in c:\\users\\visacheck admin\\anaconda3\\lib\\site-packages (0.4.3.20220106)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\visacheck admin\\anaconda3\\lib\\site-packages (from snscrape) (2.27.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\visacheck admin\\anaconda3\\lib\\site-packages (from snscrape) (4.11.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\visacheck admin\\anaconda3\\lib\\site-packages (from snscrape) (3.6.0)\n",
      "Requirement already satisfied: lxml in c:\\users\\visacheck admin\\anaconda3\\lib\\site-packages (from snscrape) (4.8.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\visacheck admin\\anaconda3\\lib\\site-packages (from beautifulsoup4->snscrape) (2.3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\visacheck admin\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\visacheck admin\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\visacheck admin\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\visacheck admin\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (1.26.9)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\visacheck admin\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install snscrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8be9e7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\users\\visacheck admin\\anaconda3\\lib\\site-packages (1.8.2.2)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\visacheck admin\\anaconda3\\lib\\site-packages (from wordcloud) (1.21.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\visacheck admin\\anaconda3\\lib\\site-packages (from wordcloud) (3.5.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\visacheck admin\\anaconda3\\lib\\site-packages (from wordcloud) (9.0.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\visacheck admin\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (4.25.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\visacheck admin\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\visacheck admin\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\visacheck admin\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\visacheck admin\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\visacheck admin\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.3.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\visacheck admin\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Requirement already satisfied: emot in c:\\users\\visacheck admin\\anaconda3\\lib\\site-packages (3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud\n",
    "!pip install emot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f6e1c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries needed\n",
    "import pandas as pd\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "# nltk.download('stopwords') #run once and comment it out to avoid it downloading multiple times\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import string\n",
    "import re\n",
    "import textblob\n",
    "from textblob import TextBlob\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from emot.emo_unicode import UNICODE_EMOJI\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "from wordcloud import ImageColorGenerator\n",
    "from PIL import Image\n",
    "\n",
    "import warnings\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4321a236",
   "metadata": {},
   "source": [
    "# Tweets scrapping\n",
    "\n",
    "The tweets were scrapped in batches to get the total of over 200000 tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "80f38e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a query for the search\n",
    "\n",
    "query = \"geocode:9.0820,8.6753,923768km since:2022-12-05 until:2022-12-07 lang:en\"\n",
    "tweets = []\n",
    "for i, tweet in enumerate(sntwitter.TwitterSearchScraper(query).get_items()):\n",
    "    if i>50000:\n",
    "        break\n",
    "    else:\n",
    "        tweets.append([tweet.date, tweet.id, tweet.url, tweet.user.username, tweet.sourceLabel, tweet.user.location, tweet.content, tweet.likeCount, tweet.retweetCount])\n",
    "df = pd.DataFrame(tweets, columns = ['Date', 'ID', 'url', 'username', 'source', 'location', 'tweet', 'num_of_likes', 'num_of_retweet'])\n",
    "df.to_csv('raw_tweet1241.csv', mode = 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cf489d",
   "metadata": {},
   "source": [
    "# Importing the File into pandas DataFrames:\n",
    "\n",
    "Seeing that the tweets was scrapped into 5 different files, we need to merge all into a single dataframe for analyis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c9537e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['raw_tweet123.csv',\n",
       " 'raw_tweet1234.csv',\n",
       " 'raw_tweet1235.csv',\n",
       " 'raw_tweet1236.csv',\n",
       " 'raw_tweet1237.csv',\n",
       " 'raw_tweet1239.csv',\n",
       " 'raw_tweet1240.csv',\n",
       " 'raw_tweet1241.csv']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we paste all the files in a single directory\n",
    "#import the modules\n",
    "import os\n",
    "#read the path\n",
    "file_path = \"C:\\\\Users\\Visacheck Admin\\\\Desktop\\\\SGA_DSCI_2\\\\Random_tweets_files\"#list all the files from the directory\n",
    "file_list = os.listdir(file_path)\n",
    "file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc5ec2d",
   "metadata": {},
   "source": [
    "Now to read multiple CSV files with the similar table structure, you can use pandas.DataFrame.append() OR pd.concat() functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c27f9be",
   "metadata": {},
   "source": [
    "Let‚Äôs look at the 3 sample CSV files we‚Äôll be working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2e56b81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files read successfully\n"
     ]
    }
   ],
   "source": [
    "#read the csv file into a dataframe\n",
    "df1 = pd.read_csv(\"C:\\\\Users\\Visacheck Admin\\\\Desktop\\\\SGA_DSCI_2\\\\Random_tweets_files\\\\raw_tweet123.csv\")\n",
    "df2 = pd.read_csv(\"C:\\\\Users\\Visacheck Admin\\\\Desktop\\\\SGA_DSCI_2\\\\Random_tweets_files\\\\raw_tweet1234.csv\")\n",
    "df3 = pd.read_csv(\"C:\\\\Users\\Visacheck Admin\\\\Desktop\\\\SGA_DSCI_2\\\\Random_tweets_files\\\\raw_tweet1235.csv\")\n",
    "df4 = pd.read_csv(\"C:\\\\Users\\Visacheck Admin\\\\Desktop\\\\SGA_DSCI_2\\\\Random_tweets_files\\\\raw_tweet1236.csv\")\n",
    "df5 = pd.read_csv(\"C:\\\\Users\\Visacheck Admin\\\\Desktop\\\\SGA_DSCI_2\\\\Random_tweets_files\\\\raw_tweet1237.csv\")\n",
    "df6 = pd.read_csv(\"C:\\\\Users\\Visacheck Admin\\\\Desktop\\\\SGA_DSCI_2\\\\Random_tweets_files\\\\raw_tweet1239.csv\")\n",
    "df7 = pd.read_csv(\"C:\\\\Users\\Visacheck Admin\\\\Desktop\\\\SGA_DSCI_2\\\\Random_tweets_files\\\\raw_tweet1240.csv\")\n",
    "df8 = pd.read_csv(\"C:\\\\Users\\Visacheck Admin\\\\Desktop\\\\SGA_DSCI_2\\\\Random_tweets_files\\\\raw_tweet1241.csv\")\n",
    "\n",
    "print('All files read successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f0f1b48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20001, 10)\n",
      "(20001, 10)\n",
      "(22434, 10)\n",
      "(22432, 10)\n",
      "(24024, 10)\n",
      "(20001, 10)\n",
      "(50001, 10)\n",
      "(46676, 10)\n"
     ]
    }
   ],
   "source": [
    "#check the shapes of the files\n",
    "\n",
    "df1.shape\n",
    "print(df1.shape)\n",
    "\n",
    "df2.shape\n",
    "print(df2.shape)\n",
    "\n",
    "df3.shape\n",
    "print(df3.shape)\n",
    "\n",
    "df4.shape\n",
    "print(df4.shape)\n",
    "\n",
    "df5.shape\n",
    "print(df5.shape)\n",
    "\n",
    "df6.shape\n",
    "print(df6.shape)\n",
    "\n",
    "df7.shape\n",
    "print(df7.shape)\n",
    "\n",
    "df8.shape\n",
    "print(df8.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aa1ee8",
   "metadata": {},
   "source": [
    "This gives a total of 205,562"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1e11f0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'ID', 'url', 'username', 'source', 'location', 'tweet',\n",
       "       'num_of_likes', 'num_of_retweet'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ec7dd8",
   "metadata": {},
   "source": [
    "Another way to do this is by using glob to list all the csv in the directory\n",
    "\n",
    "first, we have to go into the directory which has the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c53a9018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Visacheck Admin\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8a6c2c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Visacheck Admin\\Desktop\n"
     ]
    }
   ],
   "source": [
    "cd Desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "db5ad32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Visacheck Admin\\Desktop\\SGA_DSCI_2\n"
     ]
    }
   ],
   "source": [
    "cd SGA_DSCI_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c27351bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Visacheck Admin\\Desktop\\SGA_DSCI_2\\Random_tweets_files\n"
     ]
    }
   ],
   "source": [
    "cd Random_tweets_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4d61f298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['raw_tweet123.csv',\n",
       " 'raw_tweet1234.csv',\n",
       " 'raw_tweet1235.csv',\n",
       " 'raw_tweet1236.csv',\n",
       " 'raw_tweet1237.csv',\n",
       " 'raw_tweet1239.csv',\n",
       " 'raw_tweet1240.csv',\n",
       " 'raw_tweet1241.csv']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd#list all csv files only\n",
    "csv_files = glob.glob('*.{}'.format('csv'))\n",
    "csv_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f584873",
   "metadata": {},
   "source": [
    "# Combining multiple files with the similar table structure using pandas.DataFrame.append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a5346063",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Visacheck Admin\\AppData\\Local\\Temp\\ipykernel_19716\\3281929373.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_append = df_append.append(df_temp, ignore_index=True)\n",
      "C:\\Users\\Visacheck Admin\\AppData\\Local\\Temp\\ipykernel_19716\\3281929373.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_append = df_append.append(df_temp, ignore_index=True)\n",
      "C:\\Users\\Visacheck Admin\\AppData\\Local\\Temp\\ipykernel_19716\\3281929373.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_append = df_append.append(df_temp, ignore_index=True)\n",
      "C:\\Users\\Visacheck Admin\\AppData\\Local\\Temp\\ipykernel_19716\\3281929373.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_append = df_append.append(df_temp, ignore_index=True)\n",
      "C:\\Users\\Visacheck Admin\\AppData\\Local\\Temp\\ipykernel_19716\\3281929373.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_append = df_append.append(df_temp, ignore_index=True)\n",
      "C:\\Users\\Visacheck Admin\\AppData\\Local\\Temp\\ipykernel_19716\\3281929373.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_append = df_append.append(df_temp, ignore_index=True)\n",
      "C:\\Users\\Visacheck Admin\\AppData\\Local\\Temp\\ipykernel_19716\\3281929373.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_append = df_append.append(df_temp, ignore_index=True)\n",
      "C:\\Users\\Visacheck Admin\\AppData\\Local\\Temp\\ipykernel_19716\\3281929373.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_append = df_append.append(df_temp, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>ID</th>\n",
       "      <th>url</th>\n",
       "      <th>username</th>\n",
       "      <th>source</th>\n",
       "      <th>location</th>\n",
       "      <th>tweet</th>\n",
       "      <th>num_of_likes</th>\n",
       "      <th>num_of_retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01 23:59:52+00:00</td>\n",
       "      <td>1598466944507723777</td>\n",
       "      <td>https://twitter.com/Legacybozz1/status/1598466...</td>\n",
       "      <td>Legacybozz1</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>Abuja, Nigeria</td>\n",
       "      <td>@BoySpyce üòÅüôèüôèüôè</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-12-01 23:59:33+00:00</td>\n",
       "      <td>1598466865394745349</td>\n",
       "      <td>https://twitter.com/IsmailAliyuAbd3/status/159...</td>\n",
       "      <td>IsmailAliyuAbd3</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>Nigeria</td>\n",
       "      <td>But alas, kudiratu was the lucky chirp yeah? h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-12-01 23:59:26+00:00</td>\n",
       "      <td>1598466837796249600</td>\n",
       "      <td>https://twitter.com/LekkyFrosh1/status/1598466...</td>\n",
       "      <td>LekkyFrosh1</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>Lagos, Nigeria</td>\n",
       "      <td>@Objlynks @BNXN @BNXN i really want to meet yo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-12-01 23:59:25+00:00</td>\n",
       "      <td>1598466833438412802</td>\n",
       "      <td>https://twitter.com/LukenIsrael/status/1598466...</td>\n",
       "      <td>LukenIsrael</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@kelemoshane Long life and prosperity</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-12-01 23:59:25+00:00</td>\n",
       "      <td>1598466831827828736</td>\n",
       "      <td>https://twitter.com/growthmindsetll/status/159...</td>\n",
       "      <td>growthmindsetll</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>Brooklyn, New York</td>\n",
       "      <td>ingredient in creative achievement. And it was...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225565</th>\n",
       "      <td>46671</td>\n",
       "      <td>2022-12-05 00:00:25+00:00</td>\n",
       "      <td>1599554248366178305</td>\n",
       "      <td>https://twitter.com/GoldenH13843226/status/159...</td>\n",
       "      <td>GoldenH13843226</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@01gX439m2SvGo0 Yez He's Coming ObiDatti</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225566</th>\n",
       "      <td>46672</td>\n",
       "      <td>2022-12-05 00:00:19+00:00</td>\n",
       "      <td>1599554224177545217</td>\n",
       "      <td>https://twitter.com/marvix_music/status/159955...</td>\n",
       "      <td>marvix_music</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Prayer for a better day https://t.co/UWYvaZf8WM</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225567</th>\n",
       "      <td>46673</td>\n",
       "      <td>2022-12-05 00:00:19+00:00</td>\n",
       "      <td>1599554220176289792</td>\n",
       "      <td>https://twitter.com/tunji_adetomiwa/status/159...</td>\n",
       "      <td>tunji_adetomiwa</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>Lagos, Nigeria</td>\n",
       "      <td>Nowhere in the world do politicians make a lot...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225568</th>\n",
       "      <td>46674</td>\n",
       "      <td>2022-12-05 00:00:11+00:00</td>\n",
       "      <td>1599554187477458946</td>\n",
       "      <td>https://twitter.com/___Muktar/status/159955418...</td>\n",
       "      <td>___Muktar</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Abuja || kaduna</td>\n",
       "      <td>@hajjokamal Ameen thank you</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225569</th>\n",
       "      <td>46675</td>\n",
       "      <td>2022-12-05 00:00:09+00:00</td>\n",
       "      <td>1599554179999367168</td>\n",
       "      <td>https://twitter.com/CinnatiLove/status/1599554...</td>\n",
       "      <td>CinnatiLove</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>Granada, Spain</td>\n",
       "      <td>So I Dropped My New Single Today For My Birthd...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225570 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                       Date                   ID  \\\n",
       "0                0  2022-12-01 23:59:52+00:00  1598466944507723777   \n",
       "1                1  2022-12-01 23:59:33+00:00  1598466865394745349   \n",
       "2                2  2022-12-01 23:59:26+00:00  1598466837796249600   \n",
       "3                3  2022-12-01 23:59:25+00:00  1598466833438412802   \n",
       "4                4  2022-12-01 23:59:25+00:00  1598466831827828736   \n",
       "...            ...                        ...                  ...   \n",
       "225565       46671  2022-12-05 00:00:25+00:00  1599554248366178305   \n",
       "225566       46672  2022-12-05 00:00:19+00:00  1599554224177545217   \n",
       "225567       46673  2022-12-05 00:00:19+00:00  1599554220176289792   \n",
       "225568       46674  2022-12-05 00:00:11+00:00  1599554187477458946   \n",
       "225569       46675  2022-12-05 00:00:09+00:00  1599554179999367168   \n",
       "\n",
       "                                                      url         username  \\\n",
       "0       https://twitter.com/Legacybozz1/status/1598466...      Legacybozz1   \n",
       "1       https://twitter.com/IsmailAliyuAbd3/status/159...  IsmailAliyuAbd3   \n",
       "2       https://twitter.com/LekkyFrosh1/status/1598466...      LekkyFrosh1   \n",
       "3       https://twitter.com/LukenIsrael/status/1598466...      LukenIsrael   \n",
       "4       https://twitter.com/growthmindsetll/status/159...  growthmindsetll   \n",
       "...                                                   ...              ...   \n",
       "225565  https://twitter.com/GoldenH13843226/status/159...  GoldenH13843226   \n",
       "225566  https://twitter.com/marvix_music/status/159955...     marvix_music   \n",
       "225567  https://twitter.com/tunji_adetomiwa/status/159...  tunji_adetomiwa   \n",
       "225568  https://twitter.com/___Muktar/status/159955418...        ___Muktar   \n",
       "225569  https://twitter.com/CinnatiLove/status/1599554...      CinnatiLove   \n",
       "\n",
       "                     source            location  \\\n",
       "0       Twitter for Android      Abuja, Nigeria   \n",
       "1       Twitter for Android             Nigeria   \n",
       "2       Twitter for Android      Lagos, Nigeria   \n",
       "3       Twitter for Android                 NaN   \n",
       "4       Twitter for Android  Brooklyn, New York   \n",
       "...                     ...                 ...   \n",
       "225565  Twitter for Android                 NaN   \n",
       "225566  Twitter for Android                 NaN   \n",
       "225567  Twitter for Android      Lagos, Nigeria   \n",
       "225568   Twitter for iPhone     Abuja || kaduna   \n",
       "225569  Twitter for Android      Granada, Spain   \n",
       "\n",
       "                                                    tweet  num_of_likes  \\\n",
       "0                                          @BoySpyce üòÅüôèüôèüôè             0   \n",
       "1       But alas, kudiratu was the lucky chirp yeah? h...             0   \n",
       "2       @Objlynks @BNXN @BNXN i really want to meet yo...             0   \n",
       "3                   @kelemoshane Long life and prosperity             0   \n",
       "4       ingredient in creative achievement. And it was...             2   \n",
       "...                                                   ...           ...   \n",
       "225565           @01gX439m2SvGo0 Yez He's Coming ObiDatti             1   \n",
       "225566    Prayer for a better day https://t.co/UWYvaZf8WM             0   \n",
       "225567  Nowhere in the world do politicians make a lot...             0   \n",
       "225568                        @hajjokamal Ameen thank you             0   \n",
       "225569  So I Dropped My New Single Today For My Birthd...             1   \n",
       "\n",
       "        num_of_retweet  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    1  \n",
       "...                ...  \n",
       "225565               0  \n",
       "225566               0  \n",
       "225567               0  \n",
       "225568               0  \n",
       "225569               1  \n",
       "\n",
       "[225570 rows x 10 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_append = pd.DataFrame()#append all files together\n",
    "for file in csv_files:\n",
    "            df_temp = pd.read_csv(file)\n",
    "            df_append = df_append.append(df_temp, ignore_index=True)\n",
    "df_append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "15fa2636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225570, 10)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_append.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3e3907be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Date', 'ID', 'url', 'username', 'source', 'location',\n",
       "       'tweet', 'num_of_likes', 'num_of_retweet'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_append.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d100bd76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ID</th>\n",
       "      <th>url</th>\n",
       "      <th>username</th>\n",
       "      <th>source</th>\n",
       "      <th>location</th>\n",
       "      <th>tweet</th>\n",
       "      <th>num_of_likes</th>\n",
       "      <th>num_of_retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-01 23:59:52+00:00</td>\n",
       "      <td>1598466944507723777</td>\n",
       "      <td>https://twitter.com/Legacybozz1/status/1598466...</td>\n",
       "      <td>Legacybozz1</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>Abuja, Nigeria</td>\n",
       "      <td>@BoySpyce üòÅüôèüôèüôè</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-01 23:59:33+00:00</td>\n",
       "      <td>1598466865394745349</td>\n",
       "      <td>https://twitter.com/IsmailAliyuAbd3/status/159...</td>\n",
       "      <td>IsmailAliyuAbd3</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>Nigeria</td>\n",
       "      <td>But alas, kudiratu was the lucky chirp yeah? h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-01 23:59:26+00:00</td>\n",
       "      <td>1598466837796249600</td>\n",
       "      <td>https://twitter.com/LekkyFrosh1/status/1598466...</td>\n",
       "      <td>LekkyFrosh1</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>Lagos, Nigeria</td>\n",
       "      <td>@Objlynks @BNXN @BNXN i really want to meet yo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-01 23:59:25+00:00</td>\n",
       "      <td>1598466833438412802</td>\n",
       "      <td>https://twitter.com/LukenIsrael/status/1598466...</td>\n",
       "      <td>LukenIsrael</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@kelemoshane Long life and prosperity</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-01 23:59:25+00:00</td>\n",
       "      <td>1598466831827828736</td>\n",
       "      <td>https://twitter.com/growthmindsetll/status/159...</td>\n",
       "      <td>growthmindsetll</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>Brooklyn, New York</td>\n",
       "      <td>ingredient in creative achievement. And it was...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Date                   ID  \\\n",
       "0  2022-12-01 23:59:52+00:00  1598466944507723777   \n",
       "1  2022-12-01 23:59:33+00:00  1598466865394745349   \n",
       "2  2022-12-01 23:59:26+00:00  1598466837796249600   \n",
       "3  2022-12-01 23:59:25+00:00  1598466833438412802   \n",
       "4  2022-12-01 23:59:25+00:00  1598466831827828736   \n",
       "\n",
       "                                                 url         username  \\\n",
       "0  https://twitter.com/Legacybozz1/status/1598466...      Legacybozz1   \n",
       "1  https://twitter.com/IsmailAliyuAbd3/status/159...  IsmailAliyuAbd3   \n",
       "2  https://twitter.com/LekkyFrosh1/status/1598466...      LekkyFrosh1   \n",
       "3  https://twitter.com/LukenIsrael/status/1598466...      LukenIsrael   \n",
       "4  https://twitter.com/growthmindsetll/status/159...  growthmindsetll   \n",
       "\n",
       "                source            location  \\\n",
       "0  Twitter for Android      Abuja, Nigeria   \n",
       "1  Twitter for Android             Nigeria   \n",
       "2  Twitter for Android      Lagos, Nigeria   \n",
       "3  Twitter for Android                 NaN   \n",
       "4  Twitter for Android  Brooklyn, New York   \n",
       "\n",
       "                                               tweet  num_of_likes  \\\n",
       "0                                     @BoySpyce üòÅüôèüôèüôè             0   \n",
       "1  But alas, kudiratu was the lucky chirp yeah? h...             0   \n",
       "2  @Objlynks @BNXN @BNXN i really want to meet yo...             0   \n",
       "3              @kelemoshane Long life and prosperity             0   \n",
       "4  ingredient in creative achievement. And it was...             2   \n",
       "\n",
       "   num_of_retweet  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               1  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping unnamed column\n",
    "to_drop = ['Unnamed: 0']\n",
    " \n",
    "df_append.drop(to_drop, inplace=True, axis=1)\n",
    "\n",
    "df_append.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "eaa2b631",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_append.to_csv('random_cleaned_tweets.csv', mode = 'a')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
